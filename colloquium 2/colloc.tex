\documentclass[a4paper, 12pt]{article}
\usepackage{cmap}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage[left=2cm, right=2cm, top=1cm, bottom=2cm]{geometry}
\usepackage{indentfirst}
\usepackage{amsmath, amsfonts, amsthm, mathtools, amssymb, icomma, units, yfonts}
\usepackage{amsthm}
\usepackage{algorithmicx, algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{esvect}
\usepackage{enumitem}
\usetikzlibrary{calc,matrix}

\DeclareRobustCommand{\divby}{%
    \mathrel{\text{\vbox{\baselineskip.65ex\lineskiplimit0pt\hbox{.}\hbox{.}\hbox{.}}}}
}

\newcommand{\E}{\mathbb{E}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\me}{\mathbbm{e}}
\newcommand{\mf}{\mathbbm{f}}
\usepackage{bbm}  % \mathbbm{}

\usepackage{multirow}



\begin{document}
\title{Линейная алгебра.\\ Коллоквиум 2 семестр.\\ Основано на реальных событиях.\\ v0.3}
\date{26 мая 2017}

\maketitle

\part*{Ченжлоги}
v0.0 (16.05.2017) --- \textit{исходное (спасибо Борису, Глебу, Александру Г.)}

v0.1 (16.05.2017) --- \textit{поправлены графические недочёты и 5-й номер}

v0.2 (17.05.2017) --- \textit{поправлены мелкие недочёты. Добавлен 4-й, 7-й номера, а также поправлен 10-й, 13-й, 24-й (спасибо Наташе)}

v0.3 (18.05.2017) --- \textit{поправил 60, 61, 67, 68, 71, 72, 74, 82, 100, 107 (спасибо Наташе, Стасу)}

\part*{Определения}

\section*{1. Сумма двух подпространств векторного пространства}
\textbf{Сумма двух подпространств} $U$ и $W$ --- это множество $U + W: \{u + w\ |\ u \in U,\ w \in W \}$.

\textit{Замечание}. $\dim(U \cap W) \leqslant \dim U \leqslant \dim(U + W)$

\section*{2. Теорема о связи размерности суммы двух подпространств с размерностью их пересечения}
\textbf{Теорема}. $\dim(U \cap W) = \dim U + \dim W - \dim(U + W)$

\section*{3. Сумма нескольких подпространств векторного пространства}
Пусть $U_1, \ldots,\ U_k$ --- подпространства векторного пространства $V$.

\textbf{Суммой нескольких подпространств} называется
\[
U_1 + \ldots + U_k = \{u_1 + \ldots + u_k\ |\ u_i \in U_i \}
\]

\section*{4. Линейная независимость нескольких подпространств векторного пространства}
Подпространства векторного пространства $L_1, \ldots, L_k$ линейно независимы тогда и только тогда, когда: $v_1 + \ldots + v_k = 0 \Longrightarrow v_1 = \ldots = v_k = 0,\ \ v_i \in L_i.$

%%% Наталья:
\section*{5. Эквивалентные условия, определяющие линейно независимый набор подпространств векторного пространства}
Пусть $L_1 + \ldots + L_k = \{v_1 + \ldots + v_k\ |\ v_i \in L_i\}$. Тогда следующие 5 \textbf{условий} эквивалентны:
\vspace{-7mm}
\begin{enumerate}
    \itemsep=-0.3em
    \item $v_1 + \ldots + v_k = 0 \Longrightarrow v_1 = \ldots = v_k = 0$;
    \item $\forall v \in V$ единственным образом представим в виде $v = v_1 + \ldots + v_k$, где $v_i \in L_i$;
    \item если $e_i$ --- базис в $L_i$, то $e_1 \cup \ldots \cup e_k$ --- базис в $L_1 + \ldots + L_k$;
    \item $\dim(L_1 + \ldots + L_k) = \dim L_1 + \ldots + \dim L_k$;
    \item $L_i \cap (L_1 + \ldots + L_{i - 1} + L_{i + 1} + \ldots + L_k) = \{0\}$.
\end{enumerate}

\section*{6. Разложение векторного пространства в прямую сумму подпространств}
Пусть $U,\ W$ --- подпространства векторного пространства $V$.

Тогда если $U \cap W = \{0\}$, то $U \oplus W$ называется \textbf{прямой суммой}.

\section*{7. При каких условиях на подпространства $U_1$, $U_2$, векторного пространства $V$ имеет место разложение $V = U_1 \oplus U_2$?}
\begin{enumerate}
    \itemsep=0em
    \item $V = U_1 + U_2$;
    \item $U_1$ и $U_2$ --- линейно независимы ($U \cap W = \{0\}$);
    \item $\dim U + \dim W = \dim V$;
    \item любой вектор $v \in V$ единственным образом разлагается на $U + W$.
\end{enumerate}

\section*{8. Описание всех базисов n-мерного векторного пространства в терминах одного базиса и матриц координат}
Пусть $V$ --- векторное пространство, $\dim V = n$, $e_1, \ldots, e_n$ --- базис. То есть 
\[
\forall v \in V:\ \exists!\ v = x_1e_1 + \ldots + x_ne_n,
\]

где $x_1, \ldots, x_n \in F$ --- координаты вектора $v$ в базисе ($e_1, \ldots, e_n$). Пусть также есть базис $e_1', \ldots, e_n'$:
\[\begin{aligned}
e_1' &= c_{11}e_1 + c_{21}e_2 + \ldots + c_{n1}e_n \\
e_2' &= c_{12}e_1 + c_{22}e_2 + \ldots + c_{n2}e_n \\
     &\vdots \\
e_n' &= c_{1n}e_1 + c_{2n}e_2 + \ldots + c_{nn}e_n
\end{aligned}\]

Обозначим матрицу $C = (c_{ij})$.

Тогда можно переписать ($e_1', \ldots, e_n'$) как $(e_1, \ldots, e_n) \cdot C$.

\textit{Замечание}. $e_1, \ldots, e_n$ образуют базис $\Longleftrightarrow \det C \neq 0$.

\section*{9. Матрица перехода от одного базиса векторного пространства к другому}
Пусть $V$ --- векторное пространство, $\dim V = n,\ \ e_1,\ \ldots,\ e_n$ --- базис, а
$e_1',\ \ldots,\ e_n'$ --- некий набор из $n$ векторов. Тогда каждый вектор из этого набора линейно выражается через базис:
\[\begin{aligned}
                e_j' &= \sum_{i=1}^{n}c_{ij}e_i,\ \ \ c_{ij} \in F \\
(e_1', \ldots, e_n') &= (e_1, \ldots, e_n) \cdot C,\ \ \ C = (c_{ij}).
\end{aligned}\]

То есть мы получили матрицу, где в $j$-ом столбце стоят коэффициенты линейного разложения вектора $e_j'$ в базисе ($e_1, \ldots, e_n$).

Теперь пусть $e_1', \ldots, e_n'$ --- тоже базис в $V$. В этом случае $\det C \neq 0$.

Матрица $C$ называется \textbf{матрицей перехода} от базиса ($e_1, \ldots, e_n$) к базису ($e_1', \ldots, e_n'$).

\section*{10. Формула преобразования координат вектора при замене базиса векторного пространства}
Пусть $C$ --- матрица перехода от базиса ($e_1, \ldots, e_n$) к базису ($e_1', \ldots, e_n'$).
\[
\begin{pmatrix}
    x_1' \\
    x_2' \\
    \vdots \\
    x_n'
\end{pmatrix} = 
C \cdot
\begin{pmatrix}
    x_1 \\
    x_2 \\
    \vdots \\
    x_n
\end{pmatrix}\ \ \hbox{или}\ \ \
x_i' = \sum_{j=1}^{n}c_{ij}x_i
\]

\section*{11. Линейное отображение векторных пространств, его простейшие свойства.}
Пусть $V,\ W$ --- векторные пространства.

Отображение $\varphi: V \rightarrow W$ называется \textbf{линейным}, если:
\vspace{-2mm}
\begin{enumerate}
    \itemsep=-0.3em
    \item $\varphi(v_1 + v_2) = \varphi(v_1) + \varphi(v_2),\ \ \forall v_1, v_2 \in V$
    \item $\varphi(\alpha v) = \alpha \varphi(v),\ \forall \alpha \in F,\ \forall v \in V$
\end{enumerate}

\textbf{Простейшие свойства} линейного отображения:
\vspace{-2mm}
\begin{enumerate}
    \itemsep=-0.3em
    \item $\varphi(\vec{0}_V) = \vec{0}_W$
    \item $\varphi(-v) = -\varphi(v),\ \forall v \in V$
\end{enumerate}

\section*{12. Изоморфизм векторных пространств. Изоморфные векторные пространства}
Пусть $V,\ W$ --- векторные пространства над полем $F$.

Отображение $\varphi: V \rightarrow W$ называется \textbf{изоморфизмом}, если $\varphi$ линейно и биективно. \textit{Обозначение}: $\varphi: V \xrightarrow{\sim} W$.

Два векторных пространства называются \textbf{изоморфными}, если существует изоморфизм $\varphi: V \xrightarrow{\sim} W$ (и тогда существует изоморфизм $ W \xrightarrow{\sim} V$ по предположению). \textit{Обозначение}: $V \simeq W$.

\section*{13. Какими свойствами обладает отношение изоморфности на множестве всех векторных пространств?}
\textbf{Следствие из теоремы}. Изоморфизм --- это отношение эквивалентности на множестве всех векторных пространств над фиксированным полем $F$ (рефлексивность, симметричность, транзитивность).

Если $\varphi$ и $\psi$ изоморфны, то $\varphi \circ \psi$ --- тоже изоморфизм.

\section*{14. Критерий изоморфности двух конечномерных векторных пространств}
Два конечномерных векторных пространства $V$ и $W$ над полем $F$ \textbf{изоморфны} тогда и только тогда, когда $\dim V = \dim W$.

\section*{15. Матрица линейного отображения}
Пусть $V$ и $W$ --- векторные пространства, $\me = (e_1, \ldots, e_n)$ --- базис $V,\ \ \mf = (f_1, \ldots, f_m)$ --- базис $W$, $\varphi: V \rightarrow W$ --- линейное отображение. Тогда:
\vspace{-5mm}
\[
\varphi(e_j) = a_{aj}f_1 + \ldots + a_{mj}f_j = \sum_{i = 1}^{m} a_{ij}f_i.
\]

\vspace{-5mm}
Матрица $A = (a_{ij}) \in \text{Mat}_{m\times n}(F)$ называется матрицей линейного отображения $\varphi$ в базисах $\me$ и $\mf$.

\section*{16. Связь между координатами вектора и его образа при линейном отображении}
Пусть $V$ и $W$ --- векторные пространства, $\me = (e_1, \ldots, e_n)$ --- базис $V$, $\mf = (f_1, \ldots, f_m)$ --- базис $W$, $\varphi: V \rightarrow W$ --- линейное отображение. $A = A(\varphi, \me, \mf)$ --- матрица линейного отображения $\varphi$.

Если $v = x_1e_1 + \ldots + x_ne_n$ и $\varphi(v) = y_1f_1 + \ldots + y_mf_m$, то
\[
\begin{pmatrix}
y_1 \\
y_2 \\
\vdots \\
y_m
\end{pmatrix} = 
A \cdot
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix}
\]

\section*{17. Формула изменения матрицы линейного отображения при замене базисов}
Пусть $\varphi$ --- линейный \textit{оператор векторного} пространства $V$, $A$ --- матрица $\varphi$ в базисе $\me = (e_1, \ldots, e_n)$. Пусть $\me' =(e_1', \ldots, e_n')$ --- другой базис, причем
\[
(e_1', \ldots, e_n') = (e_1, \ldots, e_n) \cdot C,\ \ \ C = (c_{ij}),
\]

где $C$ --- матрица перехода, и $A'$ --- матрица $\varphi$ в базисе $\me'$. Тогда
\[
A' = C^{-1}AC.
\]

\section*{18. Сумма двух линейных отображений и ее матрица. Произведение линейного отображения на скаляр и его матрица}
Пусть $V,\ W$ --- векторные пространства $\text{Hom}(V,\ W)$ --- множество всех линейных отображений из $V$ в $W$. $\me = (e_1, \ldots, e_n)$ --- базис $V$, $\mf = (f_1, \ldots, f_m)$ --- базис $W,\ \ \varphi,\ \psi \in \text{Hom}(V,\ W)$, $\alpha \in F$, $A_\varphi$ --- матрица линейного отображения $\varphi$, $A_\psi$ --- матрица $\psi$.

\begin{enumerate}
    \itemsep=0em
    \item \textbf{Сумма} $\varphi + \psi$ --- это линейное отображение, такое что $\forall v \in V: (\varphi + \psi)(v) = \varphi(v) + \psi(v).$
    \ \ \ \textbf{Матрица суммы} линейных отображений: $A_{\varphi + \psi} = A_\varphi + A_\psi.$
    \item \textbf{Произведение} $\alpha \varphi$ --- это линейное отображение, такое что $\forall v \in V: (\alpha \phi)(v) = \alpha \phi(v).$
    \ \ \ \textbf{Матрица произведения} линейного отображения на скаляр: $A_{\alpha \varphi} = \alpha A_\varphi$
\end{enumerate}

\section*{19. Композиция двух линейных отображений и ее матрица}
Пусть $V,\ U,\ W$ --- векторные пространства. $V \xrightarrow{g} U \xrightarrow{f} W$ --- два линейных отображения. $n,\ m,\ k$ --- их размерности соответственно. $\me'',\ \me',\ \me$ --- их базисы, а $A_g,\ A_f, A_{fg}$ --- матрицы отображений в этих базисах.
\[
A_{fg} = A_fA_g
\]

\textbf{Матрица композиции линейных отображений} имеет вид:
\[
A_{fg} = \sum_{i}a_{ji}b_{ik},
\]

где $a$ --- коэффициент при $f$, а $b$ --- коэффициент при $g$.


\section*{20. Ядро и образ линейного отображения}
Пусть $V,\ W$ --- векторные пространства с линейным отображением $\varphi: V \rightarrow W$.

\textbf{Ядро} $\varphi$ --- это множество $\text{Ker}\varphi := \{v \in V\ |\ \varphi(v) = 0\}$

\textbf{Образ} $\varphi$ --- это множество $\text{Im}\varphi := \{w \in W\ |\ \exists v \in V: \varphi(v) = w\}$

\section*{21. Критерий инъективности линейного отображения в терминах его ядра. Критерий изоморфности линейного отображения в терминах ядра и образа}
Пусть $\varphi: V \rightarrow W$ --- линейное отображение.
\vspace{-1mm}
\begin{enumerate}
    \itemsep=0em
    \item Отображение $\varphi$ \textbf{инъективно} тогда и только тогда, когда $\text{Ker}\varphi = \{0\}$
    \item Отображение $\varphi$ является \textbf{изоморфизмом} тогда и только тогда, когда $\text{Ker}\varphi = \{0\}$ и $\text{Im}\varphi = W$.
\end{enumerate}

\section*{22. Связь между рангом матрицы линейного отображения и размерностью его образа}
Пусть $V,\ W$ --- векторные пространства, $\me = (e_1, \ldots, e_n)$ --- базис $V,\ \ \mf = (f_1, \ldots, f_n)$ --- базис $W$, $A$ --- матрица линейного отображения $\varphi: V \rightarrow W$.
\[
\dim \text{Im}\varphi = \text{rk}A
\]

\section*{23. Оценки на ранг произведения двух матриц}
Пусть $A \in \text{Mat}_{k \times m},\ B \in \text{Mat}_{m \times n}$. Тогда
\[
\text{rk}AB \leqslant \min(\text{rk}A, \text{rk}B)
\]

\section*{24. Каким свойством обладает набор векторов, дополняющий базис ядра линейного отображения до базиса всего пространства?}
Образы векторов, дополняющих базис ядра линейного отображения до базиса всего пространства, являются базисом образа самого пространства.

\section*{25. Теорема о связи размерностей ядра и образа линейного отображения}
\vspace{-5mm}
\[
\dim \text{Im}\varphi = \dim V - \dim \text{Ker}\varphi
\]

\section*{26. К какому простейшему виду можно привести матрицу линейного отображения путем замены базисов?}
Простейшим видом матрицы линейного отображения является её канонический вид --- диагональная матрица $D \in \text{M}_n$ вида
\[\left(
\begin{tabular}{ccc|cl}
1 & 0 & 0 & \ldots & 0 \\
0 & 1 & 0 & \ldots & 0 \\
0 & 0 & 1 & \ldots & 0 \\ \hline
\ldots & \ldots & \ldots & \ldots & 0 \\
0 & 0 & 0 & \ldots & 0
\end{tabular}
\right),\]

задаваемая формулой \[A' = D^{-1}AC\]

\section*{27. Линейная функция на векторном пространстве}
\textbf{Линейной функцией} (формой) на векторном пространстве $V$ называется всякое линейное отображение $\sigma: V \rightarrow F$. \textit{Обозначение}: $V^* = \text{Hom}(V,\ F)$.

\section*{28. Сопряженное (двойственное) векторное пространство и его размерность}
Пространство $V^*$ (т.е. множество линейных функций на $V$) называется \textbf{сопряженным} (двойственным) к пространству $V$.

Пусть $\me = (e_1, \ldots, e_n)$ --- базис $V$. Тогда он определяет изоморфизм $\varphi: V^* \rightarrow \text{Mat}_{1\times n}$, $\alpha \rightarrowtail (\alpha_1, \ldots, \alpha_n)$, где $\alpha_i = \varphi(e_i)$ и $\alpha$ --- линейная функция.
\[
\dim V^* = n.
\]

\section*{29. Базис сопряженного пространства, двойственный к данному базису исходного векторного пространства}
Пусть $\me = (e_1, \ldots, e_n)$ --- базис $V$. Рассмотрим линейные функции $\varepsilon_1, \ldots, \varepsilon_n$ такие, что $\varepsilon_i(e_j) = \delta_{ij}$, где $\delta_{ij} =
\begin{cases*}
1,\ i = j, \\
0,\ i \neq j
\end{cases*}$. То есть $\varepsilon_i = (\delta_{i1}, \ldots, \delta_{ii}, \ldots, \delta_{i_n}) = (0, \ldots, 1, \ldots, 0)$.

$(\varepsilon_1,\ \ldots,\ \varepsilon_n)$ --- \textbf{базис} $V^*$ (сопряженного пространства).

\section*{30. Билинейная форма на векторном пространстве}
\textbf{Билинейная функция} (форма) на $V$ --- это отображение $\beta: V\times V\rightarrow F$, линейное по каждому аргументу:
\vspace{-2mm}
\begin{enumerate}
    \itemsep=-0.3em
    \item $\beta(x_1 + x_2,\ y) = \beta(x_1,\ y) + \beta(x_2,\ y)$
    \item $\beta(\lambda x, y) = \lambda\beta(x, y)$
    \item аналогично 1, но по второму аргументу
    \item аналогично 2, но по второму аргументу
\end{enumerate}

\section*{31. Матрица билинейной формы}
Пусть $\me = (e_1, \ldots, e_n)$ --- базис $V$ ($\dim V < \infty$), $\beta: V\times V \rightarrow F$ --- билинейная функция.

\textbf{Матрицей билинейной функции} $\beta$ в базисе $\me$ называется матрица $B = (b_{ij})$, где $b_{ij} = \beta(e_i,\ e_j)$. \textit{Обозначение}: $B(\beta, \me)$

\section*{32. Формула для вычисления значений билинейной формы в координатах}
Пусть $\me = (e_1, \ldots, e_n)$ --- базис $V$ ($\dim V < \infty$), $\beta: V\times V \rightarrow F$ --- билинейная функция, $B$ --- её матрица в базисе $\me$.

Тогда для некоторых векторов $x = x_1e_1 + \ldots + x_ne_n \in V$ и $y = y_1e_1 + \ldots + y_ne_n \in V$:
\[
\beta(x,\ y) = (x_1,\ \ldots,\ x_n)B
\begin{pmatrix}
y_1 \\
\vdots \\
y_n
\end{pmatrix}
\]

\section*{33. Формула изменения матрицы билинейной формы при переходе к другому базису}
Пусть
\vspace{-9mm}
\begin{align*}
&\me = (e_1,\ \ldots,\ e_n) - \hbox{базис в } V, \\
&\me' = (e_1',\ \ldots,\ e_n') - \hbox{другой базис в } V, \\
&\me' = \me C, \\
&B = B(\beta, \me), \\
&B' = B(\beta, \me').
\end{align*}

Тогда \[B' = C^TBC.\]

\section*{34. Ранг билинейной формы}
Пусть $B(\beta, \me)$ --- матрица билинейной функции $\beta$ в базисе $\me$.

Число $\text{rk}B$ называется \textbf{рангом билинейной функции} $\beta$. \textit{Обозначение}: $\text{rk}\beta$.

\section*{35. Симметричная билинейная форма}
Билинейная функция $\beta$ называется \textbf{симметричной}, если $\beta(x,\ y) = \beta(y,\ x)\ \forall x,\ y \in V$.

$\beta$ симметрична $\Longleftrightarrow$ $B$ симметрична (т.е. $B = B^T$).

\section*{36. Квадратичная форма}
Пусть $\beta: V \times V \rightarrow F$ --- билинейная функция. Тогда отображение  $Q_\beta: V \rightarrow F$, заданное формулой $Q_\beta(x) = \beta(x,\ x)$ называется \textbf{квадратичной функцией} (формой), ассоциированной с билинейной функцией $\beta$.

\section*{37. Соответствие между симметричными билинейными формами и квадратичными формами}
Пусть в поле $F$ выполняется условие: $1 + 1 \neq 0$ (т.е. $2 \neq 0$).

\textbf{Теорема}. Отображение $\beta \rightarrow Q_\beta$ является биекцией между симметричными и квадратичными билинейными функциями.

\section*{38. Симметризация билинейной формы}
Билинейная функция $\sigma(x,\ y) = \frac{1}{2}(\beta(x,\ y) + \beta(y,\ x))$ называется \textbf{симметризацией билинейной функции} $\beta$.

\section*{39. Поляризация квадратичной формы}
Симметричная билинейная функция $\beta(x,\ y) = \frac{1}{2}(Q(x + y) - Q(x) - Q(y))$ называется \textbf{поляризацией квадратичной формы} $Q$.

\section*{40. Матрица квадратичной формы}
Пусть $V$ --- векторное пространство, $\dim V < \infty$.

\textbf{Матрицей квадратичной формы} $Q: V\rightarrow F$ в базисе $\me$ называется матрица соответствующей ей симметричной билинейной функции (поляризацией) $\beta: V\times V \rightarrow F$ в том же базисе.

\section*{41. Канонический вид квадратичной формы}
Квадратичная форма $Q$ имеет в базисе $\me = (e_1, \ldots, e_n)$ \textbf{канонический вид}, если для любого вектора $x = x_1e_1 + \ldots + x_ne_n$ верно, что $Q(x) = a_1x_1^2 + \ldots + a_nx_n^2$, где $a_i \in F$ (т.е. матрица квадратичной формы $Q$ в этом базисе диагональна).

\section*{42. Нормальный вид квадратичной формы над $\R$}
Квадратичная форма $Q$ имеет в базисе $\me = (e_1, \ldots, e_n)$ \textbf{нормальный вид}, если для любого вектора $x = x_1e_1 + \ldots + x_ne_n$ верно, что $Q(x) = a_1x_1^2 + \ldots + a_nx_n^2$, где $a_i \in \{-1,\ 0,\ 1\}$ (т.е. матрица квадратичной формы $Q$ в этом базисе диагональна).

\section*{43. Индексы инерции квадратичной формы над $\R$}
Пусть $Q$ --- квадратичная функция над $R$, которая в базисе $\me$ имеет нормальный вид:
\[
Q(x_1,\ \ldots,\ x_n) = x_1^2 + \ldots + x_s^2 - x_{s + 1}^2 - \ldots - x_{s + t}^2,
\]

где $s$ --- количество положительных слагаемых, $t$ --- количество отрицательных слагаемых. Тогда

$i_+ := s$ --- \textbf{положительный индекс инерции} квадратичной формы $Q$

$i_- := t$ --- \textbf{отрицательный индекс инерции} квадратичной формы $Q$

$n - s - t$ --- \textbf{нулевой индекс инерции} квадратичной формы $Q$

\section*{44. Закон инерции для квадратичной формы над R}
\textbf{Теорема}. Индексы инерции ($i_+ := s,\ i_- := t$) не зависят от базиса, в котором $Q$ принимает нормальный вид.

\section*{45. Положительно/неотрицательно определенная квадратичная форма}
Квадратичная форма $Q$ называется \textbf{положительно определённой} ($Q > 0$), если $Q(x) > 0\ \forall x \neq 0$, а её нормальный вид: $x_1^2 + \ldots + x_n^2$.

Квадратичная форма $Q$ называется \textbf{неотрицательно определённой} ($Q \geqslant 0$), если $Q(x) \geqslant 0\ \forall x$, а её нормальный вид: $x_1^2 + \ldots + x_k^2,\ k \leqslant n$.

\section*{46. Отрицательно/неположительно определенная квадратичная форма}
Квадратичная форма $Q$ называется \textbf{отрицательно определённой} ($Q < 0$), если $Q(x) < 0\ \forall x \neq 0$, а её нормальный вид: $-x_1^2 - \ldots - x_n^2$.

Квадратичная форма $Q$ называется \textbf{неположительно определённой} ($Q \leqslant 0$), если $Q(x) \leqslant 0\ \forall x$, а её нормальный вид: $-x_1^2 - \ldots - x_k^2,\ k \leqslant n$.


\section*{47. Неопределенная квадратичная форма}
Квадратичная форма называется \textbf{неопределенной}, если $\exists x,\ y: Q(x) > 0,\ Q(y) < 0$, а её нормальный вид: $x_1^2 + \ldots + x_s^2 - x_{s + 1}^2 - \ldots - x_{s + t}^2,\ \ s,\ t \geqslant 1$.

\section*{48. Следствие метода Якоби о нахождении индексов инерции  квадратичной формы}
Пусть $B = B(Q,\ \me),\ B_k = B(Q,\ \me),\ \delta_k = \det B_k$ --- $k$-й угловой минор.

\textbf{Теорема}. Пусть $\delta_k \neq 0\ \forall k = 1,\ \ldots,\ n$. Тогда $i_-$ равен числу перемен знака в последовательности $1,\ \delta_1,\ \delta_2,\ \ldots,\ \delta_n$

\section*{49. Критерий Сильвестра положительной определённости квадратичной формы}
\textbf{Теорема}. $Q > 0$ тогда и только тогда, когда $\delta_i > 0$ для всех $i$.

\section*{50. Критерий отрицательной определенности квадратичной формы}
\vspace{-5mm}
\[Q < 0 \Longleftrightarrow
\begin{cases*}
\delta_i < 0,\ i \divby 2 \\
\delta_i > 0,\ i \not{\divby}\ 2
\end{cases*}
\]

\section*{51. Евклидово пространство}
\textbf{Евклидово пространство} ($F = \R$) --- это векторное пространство $\E$ над полем $\R$, на котором задана положительно определённая симметрическая билинейная функция $(\cdot\ ,\ \cdot): \E \times \E \rightarrow \R$, которую мы будем называть произведением.

\section*{52. Длина вектора в евклидовом пространстве}
$\E$ --- евклидово пространство, $\dim\E < \infty$

\textbf{Длиной вектора} $x \in \E$ называется число $|x| = \sqrt{(x,\ x)}$. $|x| > 0$, причём $|x| = 0 \Longleftrightarrow x = 0$.

\section*{53. Неравенство Коши-Буняковского}
Пусть $x,\ y \in \E$. Тогда 
\[
|(x,\ y)| \leqslant |x||y|,
\]

причем знак равенства возможен тогда и только тогда, когда $x$ и $y$ пропорциональны.

\section*{54. Угол между ненулевыми векторами евклидова пространства}
\textbf{Углом между векторами} $x$ и $y$ называют такое число $\alpha \in [0,\ \pi]$, что
\vspace{-2mm}
\[
\cos\alpha = \dfrac{(x,\ y)}{|x||y|}.
\]
\newpage
\section*{55. Матрица Грама системы векторов евклидова пространства}
$v_1, \ldots, v_k \in \E$ --- система векторов.

Матрицей Грама системы векторов $v_1, \ldots, v_k \in \E$ называется матрица
\[
G(v_1,\ \ldots,\ v_k) :=
\begin{pmatrix}
(v_1, v_1) & (v_1, v_2) & \ldots & (v_1, v_k) \\
(v_2, v_1) & (v_2, v_2) & \ldots & (v_2, v_k) \\
\vdots     & \vdots     & \ddots & \vdots     \\
(v_k, v_1) & (v_k, v_2) & \ldots & (v_k, v_k)
\end{pmatrix} := (g_{ij}),\ \ \ g_{ij} = (v_i, v_j).
\]

\section*{56. Свойства определителя матрицы Грама}
\begin{enumerate}
    \itemsep=-0.3em
    \item $\det G(v_1,\ \ldots,\ v_k) \geqslant 0$
    \item $\det G(v_1,\ \ldots,\ v_k) = 0$ тогда и только тогда, когда $v_1,\ \ldots,\ v_k$ линейно зависимы.
\end{enumerate}

\section*{57. Ортогональное дополнение подмножества евклидова пространства}
Пусть $\E$ --- евклидово пространство, $\dim\E = n$. $S \subseteq \E$ --- произвольное подпространство. Ортогональным дополнением к $S$ называется множество $S^\bot = \{x \in \E\ |\ (x,\ y) = 0\ \forall y \in S\}$.

\section*{58. Чему равна размерность ортогонального дополнения к подпространству?}
Пусть $S \subseteq \E,\ \dim\E = n$. Тогда
\vspace{-2mm}
\[
\dim S^{\bot} = n - \dim S.
\]

\section*{59. Каким свойством обладают подпространство евклидова пространства и его ортогональное дополнение?}
Пусть $S \subseteq \E$. Тогда:
\begin{enumerate}
    \itemsep-0.3em
    \item $\E = S \oplus S^\bot$ --- евклидово пространство разлагается в прямую сумму подпространства и его ортогонального дополнения
    \item $(S^\bot)^\bot = S$ --- ортогональное дополнение ортогонального дополнения пространства есть само пространство
\end{enumerate}

\section*{60. Ортогональная проекция вектора на подпространство}
Пусть $S \subseteq \E$. Тогда $\forall x \in E$ единственным образом разбивается на сумму $x = y + z$, где $y \in S$, а $z \in S^\bot$.

Вектор $y$ называется ортогональной проекцией вектора $x$ на подпространство $S$.

\textit{Обозначение}: $pr_sx$.

\section*{61. Ортогональная составляющая вектора относительно подпространства}
Пусть $S \subseteq \E$. Тогда $\forall x \in E$ единственным образом разбивается на сумму $x = y + z$, где $y \in S$, а $z \in S^\bot$.

Вектор $z$ называется ортогональной составляющей вектора $x$ вдоль подпространства $S$. \textit{Обозначение}: $ort_sx$.

\section*{62. Формула для ортогональной проекции вектора на подпространство в $\R^n$, заданное своим базисом}
Пусть $\E = \R^n$ со стандартным скалярным произведением. $S \subseteq \R^n$ --- подпространство, $a_1, \ldots, a_k$ --- базис в $S$.

Образуем матрицу $A \in \text{Mat}_{n \times k}(\R)$, где $A^{(i)} = a_i$.
\[
\forall v \in \E: pr_sv = A(A^TA)^{-1}A^Tv
\]

\section*{63. Ортогональная система векторов. Ортогональный базис}
\textbf{Система} векторов $v_1, \ldots, v_k$ евклидова пространства называется \textbf{ортогональной}, если все её векторы попарно ортогональны, т.е. $(e_i,\ e_j) = 0\ \forall i \neq j$.

\textbf{Базис} $(e_1, \ldots, e_n)$ в $\E$ называется \textbf{ортогональным}, если $(e_i,\ e_j) = 0\ \forall i \neq j$. Это равносильно тому, что $G(e_1, \ldots, e_n)$ диагональна.

\section*{64. Ортонормированная система векторов. Ортонормированный базис}
\textbf{Система} векторов $v_1,\ \ldots,\ v_k$ евклидова пространства называется \textbf{ортонормированной}, если все её векторы попарно ортогональны, т.е. $(e_i,\ e_j) = 0\ \forall i \neq j$, и длина (норма) каждого вектора системы равна 1.

\textbf{Базис} $(e_1, \ldots, e_n)$ в $\E$ называется \textbf{ортонормированным}, если $(e_i,\ e_j) = 0\ \forall i \neq j$ и длина каждого вектора равна 1: 
$\left(
\dfrac{e_1}{|e_1|},\ \ldots,\ \dfrac{e_n}{|e_n|}
\right)$.

\section*{65. Описание всех ортонормированных базисов евклидова пространства в терминах одного такого базиса и матриц перехода}
Пусть $(e_1, \ldots, e_n)$ --- ортонормированный базис в $\E$. Пусть также есть ещё один базис $(e_1', \ldots, e_n')$, причём $(e_1', \ldots, e_n') = (e_1, \ldots, e_n) \cdot C$.

$(e_1', \ldots, e_n')$ --- \textbf{ортонормированный} тогда и только тогда, когда $C^TC = E$ или, что то же самое, $C^{-1} = C^T$.

\section*{66. Ортогональная матрица}
Матрица $C \in \text{Mat}_n(\R)$ называется \textbf{ортогональной}, если $C^TC = E$ или, что то же самое, $C^{-1} = C^T$.

\textit{Из матана}: $C$ --- ортогональна $\Longleftrightarrow$ её столбцы образуют ортонормированный базис (сумма квадратов координат по столбцам равна единице).

\section*{67. Формула для ортогональной проекции вектора на подпространство в терминах его ортогонального базиса}
Пусть $S \subseteq \E$ --- подпространство, $(e_1, \ldots, e_k)$ --- его ортогональный базис, $x \in \E$.
\[
pr_Sx = \sum_{i = 1}^{k}\dfrac{(x,\ e_i)}{(e_i,\ e_i)}e_i\ \hbox{--- для ортогонального базиса}
\]
\[
pr_Sx = \sum_{i = 1}^{k}(x,\ e_i)e_i\ \hbox{--- для ортонормированного базиса}
\]

\section*{68. Теорема Пифагора в евклидовом пространстве}
Пусть $x, y \in \E$ и $x \bot y$ ($(x,\ y) = 0$). Тогда
\vspace{-2mm}
\[
|x + y|^2 = |x|^2 + |y|^2.
\]

\section*{69. Расстояние между векторами евклидова пространства}
Рассмотрим векторы $x,\ y \in \E$.

\textbf{Расстоянием} между двумя векторами называется величина
\vspace{-2mm}
\[
\rho(x,\ y) := |x - y|.
\]

\section*{70. Неравенство треугольника в евклидовом пространстве}
\vspace{-7mm}
\[
\rho(a,\ b) + \rho(b,\ c) \geqslant \rho(a,\ c)\ \ \forall a, b, c \in \E.
\]

\section*{71. Теорема о расстоянии между вектором и подпространством в терминах ортогональной составляющей}
Пусть $x \in \E$ и $S \subseteq \E$ --- подпространство.

\textbf{Теорема}. $\rho(x,\ S) = |ort_Sx|$, причём $pr_Sx$ -- единственный ближайший к $x$ вектор из $S$.

\section*{72. Псевдорешение несовместной системы линейных уравнений}
\textit{Метод наименьших квадратов}:

Имеем СЛУ(*) $Ax = b$, где $A \in \text{Mat}_{m \times n},\ x \in \R^n$ --- вектор неизвестных, $b \in \R^m$.

$x_0 \in \R^n$ --- решение СЛУ(*) $\Leftrightarrow$ $Ax_0 = b$ $\Leftrightarrow$ $Ax_0 - b = 0$ $\Leftrightarrow$ $|Ax_0 - b| = 0$ (где $\R^n$ рассматривается как евклидово пространство со стандартным скалярным произведением) $\Leftrightarrow$ $\rho(Ax_0,\ b) = 0$.

В случае, когда СЛУ(*) несовместна, набор $x_0 \in \R^n$ (вектор-столбец) называется \textbf{псевдорешением}, если $\rho(Ax_0,\ b) = \min\rho(Ax,\ b)$.

\section*{73. Формула для расстояния от вектора до подпространства в терминах матриц Грама}
Пусть $S$ --- подпространство евклидова пространства $\E$, $x \in \E$, $(e_1, \ldots, e_n)$ --- базис $S$.

Тогда
\[
(\rho(x,\ S))^2 =  \dfrac{\det G(e_1, \ldots, e_k, x)}{\det G(e_1, \ldots, e_k)}
\]

\section*{74. $k$-мерный параллелепипед и его объём}
\textbf{$k$-мерным параллелепипедом}, натянутым на векторы $a_1, \ldots, a_k$, называется подмножество
\[
P(a_1, \ldots, a_k) := \left\{ x = \sum_{i = 1}^{k} x_ia_i\ |\ 0 \leqslant x_i \leqslant 1 \right\}.
\]

Объем $k$-мерного параллелепипеда --- это величиина $volP(a_1, \ldots, a_n)$, определяемая индуктивно:
\begin{align*}
k &= 1 \Rightarrow volP(a_1) := |a_1| \\
k &> 1 \Rightarrow volP(a_1, \ldots, a_k) := \underbracket{volP(a_1, \ldots, a_{k - 1})}_{\text{основание}} \cdot \underbracket{|h|}_{\text{высота}},\ \text{где $h = \text{ort}_{\langle a_1, \ldots, a_{k - 1}\rangle}a_k$}
\end{align*}

\section*{75. В каком случае два базиса евклидова пространства называются одинаково ориентированными?}
Одинаковая ориентированность --- отношение эквивалентности на множестве всех базисов в $\E$.

Пусть $\me,\ \me'$ --- два базиса пространства.

Будем говорить, что базисы $\me,\ \me'$ \textbf{ориентированны одинаково}, если определитель матрицы перехода от $\me$ к $\me'$ больше нуля ($\det C > 0$).

\section*{76. Смешанное произведение векторов трёхмерного евклидова пространства, формула для его вычисления в терминах координат в правом ортонормированном базисе}
Правый ортонормированный базис --- положительно ориентированный.

\textbf{Смешанным произведением векторов} $a, b, c$ называется \underline{величина} $(a,\ b,\ c) = vol(a,\ b,\ c)$.

Если $(e_1, e_2, e_3)$ --- правый ортонормированный базис и
\vspace{-2mm}
\begin{align*}
a &= a_1e_1 + a_2e_2 + a_3e_3 \\
b &= b_1e_1 + b_2e_2 + b_3e_3 \\
c &= c_1e_1 + c_2e_2 + c_3e_3,
\end{align*}

\vspace{-3mm}
то
\vspace{-2mm}
\[
(a,\ b,\ c) = 
\begin{vmatrix}
a_1 & a_2 & a_3 \\
b_1 & b_2 & b_3 \\
c_1 & c_2 & c_3
\end{vmatrix}
\]

\section*{77. Критерий компланарности трёх векторов трёхмерного евклидова пространства}
Векторы $a, b, c$ \textbf{компланарны} (линейно зависимы) $\Longleftrightarrow$ $(a, b, c) = 0$.

\section*{78. Векторное произведение в трёхмерном евклидовом пространстве}
\textbf{Векторным произведением векторов} $a, b \in \E$ называется \underline{вектор} $c$ такой, что:
\begin{enumerate}
    \itemsep=-0,3em
    \item $c\ \bot\ \langle a,\ b \rangle$
    \item $|c| = |a||b|\sin\alpha$ (или же $|c| =$ площади параллелограмма, образованного $(a, b)$)
    \item $(a,\ b,\ c) \geqslant 0$ (т.е. векторы образуют правую тройку)
\end{enumerate}

\textit{Обозначение}: $[a, b]$ или $a \times b$.

\section*{79. Критерий коллинеарности двух векторов трёхмерного евклидова пространства}
$a, b$ \textbf{коллинеарны} (т.е. линейно зависимы) $\Longleftrightarrow$ $[a, b] = 0$.

\section*{80. Выражение смешанного произведения через векторное и скалярное в трёхмерном евклидовом пространстве}
\[
\forall a, b, c \in \R^3:\ (a, b, c) = (a, [b, c])
\]

\section*{81. Формула для двойного векторного произведения в трёхмерном евклидовом пространстве}
\vspace{-7mm}
\begin{align*}
[a, [b, c]] = (a, c)b - (a, b)c = \\
              = b(a, c) - c(a, b)
\end{align*}

\section*{82. Формула для вычисления векторного произведения в терминах координат в правом ортонормированном базисе}
Пусть $(e_1, e_2, e_3)$ --- ортонормированный базис.
\vspace{-2mm}
\begin{align*}
a &= a_1e_1 + a_2e_2 + a_3e_3 \\
b &= b_1e_1 + b_2e_2 + b_3e_3
\end{align*}

\vspace{-2mm}
Тогда
\vspace{-2mm}
\begin{align*}
[a,\ b] =
\begin{vmatrix}
e_1 & e_2 & e_3 \\
a_1 & a_2 & a_3 \\
b_1 & b_2 & b_3
\end{vmatrix} =
e_1
\begin{vmatrix}
a_2 & a_3 \\
b_2 & b_3
\end{vmatrix}
- e_2
\begin{vmatrix}
a_1 & a_3 \\
b_1 & b_3
\end{vmatrix}
+ e_3
\begin{vmatrix}
a_1 & a_2 \\
b_1 & b_2
\end{vmatrix} = \\
= (a_2b_3 - b_2a_3)e_1 - (a_1b_3 - b_1a_3)e_2 + (a_1b_2 - b_1a_2)e_3 = \\
= \underline{((a_2b_3 - b_2a_3),\ (b_1a_3 - a_1b_3),\ (a_1b_2 - b_1a_2))}
\end{align*}

\section*{83. Линейное многообразие. Характеризация линейных многообразий как сдвигов подпространств}
\textbf{Линейное многообразие} в $\R^n$ --- множество решений некоторой совместной СЛУ.

\section*{84. Критерий равенства двух линейных многообразий. Направляющее подпространство и размерность линейного многообразия}
$L_1,\ L_2 \subseteq \R^n$ --- множества всех решений. $S_1,\ S_2 \subseteq \R^n$ --- множество решений однородной СЛУ $Ax = 0$.

$L_1 = v_1 + S_1$ и $L_2 = v_2 + S_2$ --- два линейных многообразия.

\vspace{-2mm}
\[
L_1 = L_2 \Longleftrightarrow
\begin{cases*}
S_1 = S_2\ (=S), \\
v_1 - v_2 \in S
\end{cases*}
\]

$S$ называется \textbf{направляющим подпространством} линейного многообразия $L$.

\section*{85. Теорема о плоскости, проходящей через точку $k + 1$ в $\R^n$}
\textbf{Теорема}. a) Через любые $k + 1$ точек в $\R^n$ проходит плоскость размерности $\leqslant k$

\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ б) Если $k + 1$ точек не лежат в плоскости размерности $< k$, то через них

\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ проходит ровно одна плоскости размерности $k$

\section*{86. Три способа задания прямой в $\R^2$. Уравнение прямой в $\R^2$, проходящей через две различные точки}
\begin{enumerate}
    \itemsep0em
    \item \textbf{Уравнение в координатах}: $Ax + By = C,\ \ (A,\ B) \neq (0,\ 0)$
    \item \textbf{Векторное уравнение}: $(\vec{n},\ v - v_0) = 0$, где $\vec n$ --- вектор нормали, $v - v_0$ принадлежит прямой
    \item \textbf{Параметрическое уравнение}: $v = v_0 + \vec{a}\lambda$, где $v_0$ --- точка на прямой, $\vec{a}$ --- направляющий вектор прямой, $\lambda$ --- коэффициент
\end{enumerate}

\textbf{Уравнение прямой, проходящей через две точки} $(x_0,\ y_0)$ и $x_1,\ y_1$:
\[
\begin{vmatrix}
x - x_0 & y - y_0 \\
x_1 - x_0 & y_1 - y_0
\end{vmatrix} = 0
\ \ \ \text{или}\ \ \
\dfrac{x - x_0}{x_1 - x_0} = \dfrac{y - y_0}{y_1 - y_0}
\]

\section*{87. Три способа задания плоскости в $\R^3$. Уравнение плоскости в $\R^3$, проходящей через три точки, не лежащие на одной прямой}
\begin{enumerate}
    \itemsep0em
    \item \textbf{Уравнение в координатах}: $Ax + By + Cz = D,\ \ (A,\ B,\ C) \neq (0,\ 0,\ 0)$
    \item \textbf{Векторное уравнение}: $(\vec n,\ v - v_0 = 0)$, где $\vec n$ --- нормальный вектор плоскости, $v - v_0$ --- вектор на плоскости
    \item \textbf{Параметрическое уравнение}: $v = v_0 + \vec a\alpha + \vec b\beta$, где $v_0 --- точка на плоскости$, $a,\ b$ --- направляющие векторы на плоскости
\end{enumerate}

\textbf{Уравнение плоскости, проходящей через точки} $(x_0, y_0, z_0)$, $(x_1, y_1, z_1)$, $(x_2, y_2, z_2)$:
\[
\begin{vmatrix}
x - x_0 & y - y_0 & z - z_0 \\
x_1 - x_0 & y_1 - y_0 & z_1 - z_0 \\
x_2 - x_0 & y_2 - y_0 & z_2 - z_0 \\
\end{vmatrix} = 0
\]

\section*{88. Три способа задания прямой в $\R^3$. Уравнения прямой в $\R^3$, проходящей через две различные точки}
\begin{enumerate}
    \itemsep0em
    \item \textbf{СЛУ}: $
        \begin{cases*}
            A_1x + B_1y + C_1z = D_1 \\
            A_2x + B_2y + C_2z = D_2
        \end{cases*}
         $
    \item \textbf{Векторное уравнение}: $[v - v_0,\ a] = 0$, где $v - v_0$ принадлежит прямой, $\vec a$ --- направляющий вектор
    \item \textbf{Параметрическое уравнение}: $v = v_0 + \vec a\lambda$, где $v_0$ --- точка на прямой, $\vec a$ --- направляющий вектор
    \item \textbf{Каноническое уравнение прямой}: $\dfrac{x - x_0}{a_1} = \dfrac{y - y_0}{a_2} = \dfrac{z - z_0}{a_3}$, где $a_1,\ a_2,\ a_3$ --- направляющий вектор, $x_0,\ y_0,\ z_0$ --- координаты точки на прямой
\end{enumerate}

Уравнение прямой, проходящей через две различные точки $(x_0,\ y_0,\ z_0)$ и $(x_1,\ y_1,\ z_1)$:
\[
\dfrac{x - x_0}{x_1 - x_0} = \dfrac{y - y_0}{y_1 - y_0} = \dfrac{z - z_0}{z_1 - z_0}
\]

\section*{89. Случаи взаимного расположения двух прямых в $\R^3$}
Пусть $a_1,\ a_2$ --- направляющие прямых $l_1,\ l_2$, а $v_1,\ v_2$ --- точки, лежащие на данных прямых. Тогда прямые $l_1,\ l_2$:
\begin{align*}
&\begin{rcases*}
    1. \text{ совпадают} \\
    2. \text{ параллельны} \\
    3. \text{ пересекаются в точке }
\end{rcases*} \text{ лежат в одной плоскости} \Rightarrow (a_1,\ a_2,\ v_2 - v_1) = 0 \\
&\ 4. \text{ скрещиваются или не лежат в одной плоскости}
\end{align*}

\section*{90. Случаи взаимного расположения трёх попарно различных плоскостей в $\R^3$}
Пусть имеются три плоскости $P_1,\ P_2,\ P_3$.
\begin{enumerate}
    \itemsep0em
    \item Среди $P_1,\ P_2,\ P_3$ есть две параллельных
          \vspace{-3mm}
          \begin{enumerate}
              \itemsep0em
              \item $P_1 \parallel P_2 \parallel P_3$
              \item Две параллельны, а третья их пересекает
          \end{enumerate}
    \item Никакие две плоскости не параллельны
          \vspace{-3mm}
          \begin{enumerate}
              \itemsep0em
              \item Все три пересекаются по одной прямой
              \item Прямые пересечения параллельны
              \item $P_1,\ P_2,\ P_3$ пересекаются в одной точке
          \end{enumerate}
\end{enumerate}

\section*{91. Формула для расстояния от точки до прямой в $\R^3$}
Пусть $l$ --- прямая, $v$ --- точка, не лежащая на данной прямой, $a$ --- направляющий вектор прямой.

\[
\rho(v,\ l) = |ort_{\langle a \rangle}(v - v_0)| = \dfrac{[v - v_0,\ a]}{|a|}
\]

\section*{92. Формула для расстояния от точки до плоскости в $\R^3$}
Пусть $P$ --- плоскость, $n$ --- вектор нормали, $v_0$ --- точка, лежащая на плоскости, $v$ --- точка, не лежащая на плоскости, $S = \langle n \rangle^\bot$ --- направляющее подпространство.

\[
\rho(v,\ P) = |ort_S(v - v_0)| = |pr_{\langle n \rangle}(v - v_0)| = \left|\dfrac{(v - v_0,\ n)}{(n,\ n)}n\right| = \dfrac{|(v - v_0,\ n)|}{|n|}
\]

\section*{93. Формула для расстояния между двумя скрещивающимися прямыми в $\R^3$}
Пусть $l_1,\ l_2$ --- прямые. $v_1,\ v_2$ --- точки, лежащие на каждой из данных прямых. $a_1,\ a_2$ --- их направляющие векторы.

Построим плоскости
\vspace{-2mm}
\begin{align*}
P_1 = v_1 + \langle a_1,\ a_2 \rangle \supseteq l_1 \\
P_2 = v_2 + \langle a_1,\ a_2 \rangle \supseteq l_2
\end{align*}

Тогда
\vspace{-2mm}
\[
\rho(l_1,\ l_2) = \rho(P_1,\ P_2) = \dfrac{|(a_1,\ a_2,\ v_2 - v_1)|}{|[a_1,\ a_2]|}
\]


\section*{94. Линейный оператор}
Пусть $V$ --- конечномерное векторное пространство.

\textbf{Линейным оператором} (преобразованием) называется всякое линейное отображение $\varphi: V \rightarrow V$, то есть из $V$ в себя. \textit{Обозначение}: $L(V) = \text{Hom}(V,\ V)$.

\section*{95. Матрица линейного оператора}
Пусть $V$ --- векторное пространство, $\me = (e_1, \ldots, e_n)$ --- его базис и $\varphi$ --- его линейный оператор.

\textbf{Матрицей линейного оператора} $\varphi$ называется такая матрица, в $j$-ом столбце которой стоят координаты вектора $\varphi(e_j)$ в базисе $\me$.
\[
(\varphi(e_1), \ldots, \varphi(e_n)) = (e_1, \ldots, e_n) A,\ \ \ A \in \text{Mat}_n.
\]

\section*{96. Формула преобразования координат вектора при действии линейного оператора}
Пусть $\varphi \in L(V)$, $A$ --- матрица $\varphi$ в базисе $\me$. Тогда
\begin{align*}
v = x_1e_1 + \ldots + x_ne_n, \\
\varphi(v) = y_1e_1 + \ldots + y_ne_n, \\
\begin{pmatrix}
y_1 \\
\vdots \\
y_n
\end{pmatrix} = A
\begin{pmatrix}
x_1 \\
\vdots \\
x_n
\end{pmatrix}
\end{align*}

\section*{97. Формула изменения матрицы линейного оператора при переходе к другому базису}
Пусть $\varphi$ --- линейный оператор векторного пространства $V$, $A$ --- матрица $\varphi$ в базисе $\me = (e_1, \ldots, e_n)$. Пусть $\me' = (e_1', \ldots, e_n')$ --- другой базис, причём $(e_1', \ldots, e_n') = (e_1, \ldots, e_n)C$. 

Тогда
\[
A' = C^{-1}AC,
\]

где $C$ --- матрица перехода к новому базису $\me'$, $A'$ --- матрица $\varphi$ в базисе $\me'$.

\section*{98. Подобные матрицы}
Две матрицы $A',\ A \in \text{M}_n(F)$ называются \textbf{подобными}, если существует такая матрица $C \in \text{M}_n(F)$,  $\det C \neq 0$, что $A' = C^{-1}AC$.

\section*{99. Подпространство, инвариантное относительно линейного оператора}
Подпространство $U \subseteq V$ называется \textbf{инвариантным} относительно $\varphi$ (или $\varphi$-инвариантным), если $\varphi(U) \subseteq U$. То есть $\forall u \in U: \varphi(u) \in U$.

\section*{100. Матрица линейного оператора в базисе, дополняющем базис инвариантного подпространства}
Пусть $\varphi: V \rightarrow V$ --- линейный оператор.

Пусть $U \subset V$ --- $\varphi$-инвариантное подпространство. Также пусть $e_1,\ \ldots,\ e_k$ --- базис в $U$. Дополним его до базиса $V:\ \me = (e_1,\ \ldots,\ e_n)$. Тогда
\vspace{-2mm}
\[
\underbracket{A(\varphi, \me)}_{\text{матрица с углом нулей}} =
\begin{pmatrix}
B & C \\
0 & D
\end{pmatrix},\ \ \ \hbox{где } B \in \text{M}_k.
\]

\section*{101. Собственный вектор линейного оператора}
Пусть $\varphi: V \rightarrow V$ --- линейный оператор.

Ненулевой \textbf{вектор} $v \in V$ называется \textbf{собственным} для $V$, если $\varphi(v) = \lambda v$ для некоторого $\lambda \in F$.

\section*{102. Собственное значение линейного оператора}
Элемент $\lambda \in F$ называется \textbf{собственным значением} линейного оператора $\varphi: V \rightarrow V$, если существует такой ненулевой вектор $v \in V$, что $\varphi(v) = \lambda v$.

\section*{103. Спектр линейного оператора}
Множество всех собственных значений линейного оператора $\varphi$ называется \textbf{спектром}. \textit{Обозначение}: $\text{Spec}(\varphi)$.

\section*{104. Диагонализуемый линейный оператор}
Линейный оператор $\varphi$ называется \textbf{диагонализуемым}, если существует такой базис $\me$, что $A(\varphi,\ \me)$ --- диагональная матрица, т.е. $A(\varphi,\ \me) = diag(\lambda_1, \ldots, \lambda_n)$

\section*{105. Критерий диагонализуемости линейного оператора в терминах собственных векторов}
Линейный оператор $\varphi$ диагонализуем тогда и только тогда, когда в $V$ есть базис из собственных векторов для $\varphi$.

\section*{106. Собственное подпространство линейного оператора}
Пусть $\lambda \in \text{Spec}(\varphi)$.

Множество $V_\lambda(\varphi) = \{v \in V\ |\ \varphi(v) = \lambda v\}$ называется \textbf{собственным подпространством} линейного оператора, отвечающим собственному значению $\lambda$.

\section*{107. Характеристический многочлен линейного оператора}
Пусть $A_\varphi$ --- матрица линейного оператора $\varphi$, а $t \in F$.

Многочлен $\chi_\varphi(t) := (-1)^{n} \det (A_\varphi - t E)$ называется \textbf{характеристическим многочленом} линейного оператора $\varphi$.

\section*{108. Связь спектра линейного оператора с его характеристическим многочленом}
Пусть $\lambda \in \text{Spec}(\varphi)$.
\vspace{-2mm}
\[
\chi_\varphi(\lambda) = 0,
\]

то есть $\lambda$ --- корень характеристического многочлена.

\newpage
\section*{109. Алгебраическая кратность собственного значения линейного оператора}
Пусть $\varphi: V \rightarrow V$ --- линейный оператор, $\lambda$ --- его собственное значение.

\textbf{Алгебраической кратностью} собственного значения $\lambda$ линейного оператора $\varphi$ называется такое число $k$, которое равняется кратности $\lambda$ как корня характеристического многочлена.

\section*{110. Геометрическая кратность собственного значения линейного оператора}
Пусть $\varphi: V \rightarrow V$ --- линейный оператор, $\lambda$ --- его собственное значение, $V_\lambda(\varphi)$ --- соответствующее собственное подпространство.

\textbf{Геометрической кратностью} собственного значения $\lambda$ называется число $\dim V_\lambda(\varphi)$ (проще говоря --- количество линейно независимых векторов в ФСР матрицы, образованной $\lambda$).

\section*{111. Связь между алгебраической и геометрической кратностями собственного значения линейного оператора}
Пусть $a_i$ --- алгебраическая кратность собственного значения, $s_i$ --- геометрическая кратность. Тогда справедливо неравенство
\vspace{-4mm}
\[
s_i \leqslant a_i
\]

\section*{112. Критерий диагонализуемости линейного оператора в терминах его характеристического многочлена и кратностей его собственных значений}
Линейный оператор $\varphi: V \rightarrow V$ диагонализуем тогда и только тогда, когда:
\vspace{-2mm}
\begin{itemize}
    \itemsep0em
    \item $\chi_\varphi(t)$ разлагается на линейные множители
    \item Для любого собственного значения $\varphi$ геометрическая кратность равна алгебраической
\end{itemize}

\end{document}